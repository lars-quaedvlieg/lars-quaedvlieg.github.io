<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS-330 Lecture 2: Transfer Learning and Meta-Learning | Lars C.P.M. Quaedvlieg</title>
    <meta name="author" content="Lars C.P.M. Quaedvlieg" />
    <meta name="description" content="This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to transfer knowledge from one task to another, discuss what it means for two tasks to share a common structure, and start thinking about meta learning." />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/default.css" media="" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2024/cs330-stanford-tl-ml/">
    
    <!-- Dark Mode -->
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "CS-330 Lecture 2: Transfer Learning and Meta-Learning",
      "description": "This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to transfer knowledge from one task to another, discuss what it means for two tasks to share a common structure, and start thinking about meta learning.",
      "published": "March 3, 2024",
      "authors": [
        {
          "author": "Lars C.P.M. Quaedvlieg",
          "authorURL": "https://lars-quaedvlieg.github.io/",
          "affiliations": [
            {
              "name": "EPFL",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Lars C.P.M. Quaedvlieg</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Curriculum Vitae</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>CS-330 Lecture 2: Transfer Learning and Meta-Learning</h1>
        <p>This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to transfer knowledge from one task to another, discuss what it means for two tasks to share a common structure, and start thinking about meta learning.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#transfer-learning">Transfer learning</a></div>
            <ul>
              <li><a href="#transfer-learning-through-fine-tuning">Transfer learning through fine-tuning</a></li>
              
            </ul>
<div><a href="#introduction-to-meta-learning">Introduction to meta learning</a></div>
            <ul>
              <li><a href="#a-probabilistic-view-on-meta-learning">A probabilistic view on meta learning</a></li>
              <li><a href="#how-does-meta-learning-work">How does meta learning work?</a></li>
              <li><a href="#a-general-recipe-for-meta-learning-algorithms">A general recipe for meta learning algorithms</a></li>
              
            </ul>
          </nav>
        </d-contents>

        <p>The goal of this lecture is to learn how to transfer knowledge from one task to another, discuss what it means for two 
tasks to share a common structure, and start thinking about meta learning. If you missed the previous lecture, which was
about multi-task learning, you can head over <a href="/blog/2024/cs330-stanford-mtl/">here</a> to view it.</p>

<p>As always, since I am still new to this blogging thing, reach out to me if you have any feedback on my writing, the flow 
of information, or whatever! You can contact me through <a href="https://www.linkedin.com/in/lars-quaedvlieg/" target="_blank" rel="noopener noreferrer">LinkedIn</a>. ☺</p>

<p>The link to the lecture slides can be found <a href="https://cs330.stanford.edu/materials/cs330_finetune_transfer_meta_learning_problem_setup_2023.pdf" target="_blank" rel="noopener noreferrer">here</a>.</p>

<h2 id="transfer-learning">Transfer learning</h2>

<p>In contrast to multi-task learning, which tackles several tasks $\mathcal{T}_1, \dots, \mathcal{T}_i$ simultaneously, 
transfer learning takes a sequential approach. It focuses on mastering a specific task $\mathcal{T}_b$ after the 
knowledge has been acquired from source task(s) $\mathcal{T}_a$. A common assumption is that $\mathcal{D}_a$ cannot be 
accessed during the transfer.</p>

<p>Transfer learning is a valid solution to multi-task learning, because it can sequentially apply knowledge from one task 
to another. This is unlike multi-task learning, which requires simultaneous learning of all tasks.</p>

<p>It is advantageous in the case of a large dataset $\mathcal{D}_a$, where continuous retraining is not feasible. Transfer
learning makes sense here by utilizing the acquired knowledge without the need for repetitive training on the large
dataset. Additionally, when you do not need to train two tasks simultaneously, you might opt to solve it them 
sequentially using transfer learning.</p>

<h3 id="transfer-learning-through-fine-tuning">Transfer learning through fine-tuning</h3>

\[\phi \leftarrow \theta - \alpha \nabla_\theta \mathcal{L}(\theta, \mathcal{D}_\mathrm{tr})\;.\]

<p>One method of transfer learning involves the fine-tuning of a pre-trained model with parameters $\theta$. This process 
starts with a model whose parameters have been <b>initially trained on a large, diverse dataset</b>, such as ImageNet <d-cite key="huh2016makes"></d-cite>.
The usefulness of fine-tuning lies in its ability to adapt these pre-trained parameters to a new task $\mathcal{T}_b$ by
continuing the training process with a dataset $\mathcal{D}_\mathrm{tr}$ specific to that task. Typically, this involves 
many iterations of gradient descent steps, where the pre-trained model's parameters $\theta$ are updated by moving in the
direction that minimizes the loss $\mathcal{L}$. This optimization process is depicted in the equation above.</p>

<p>When utilizing fine-tuning for transfer learning, there are several common design choices that are usually considered:</p>

<ul>
  <li>Opting for a <strong>lower learning rate</strong> to prevent the overwriting of the knowledge captured during pre-training.</li>
  <li>Employing even <strong>smaller learning rates for the earlier layers</strong> of the network, preserving more generic features.</li>
  <li>Initially <strong>freezing the early layers</strong> of the model, then gradually unfreezing them as training progresses.</li>
  <li>
<strong>Reinitializing the last layer</strong> to tailor it to the specifics of the new task.</li>
  <li>
<strong>Searching over hyperparameters</strong> using cross-validation to find the optimal configuration.</li>
  <li>Making smart choices about the <strong>model architecture</strong>.</li>
</ul>

<figure class="figure col-sm-11 float-right">
    <img src="/assets/img/blog/cs330/3/pretraining_datasets.png" class="img-fluid" alt="Alt text.">
    <figcaption class="figure-caption text-center"> Aggregate performance of a model across 10 finetuning datasets when it is (i) randomly 
    initialized (ii) pretrained on upstream corpus (BookWiki) (iii) pretrained on the finetuning dataset itself.</figcaption>
</figure>

<p>❗However, this common knowledge does not always hold true. For example, when using unsupervised pre-trained objectives,
you may not require diverse data for pre-training. The figure above shows that a model that was pretrained on the 
downstream dataset performs similarly to an upstream corpus such as BookWiki <d-cite key="krishna2022downstream"></d-cite>.</p>

<figure class="figure col-sm-11 float-right">
    <img src="/assets/img/blog/cs330/3/layer_tuning.png" class="img-fluid" alt="Alt text.">
    <figcaption class="figure-caption text-center"> How fine-tuning different layers has different effects.</figcaption>
</figure>

<p>Furthermore, depending on the downstream task, it may be better to tune the first or middle layers, rather than the last
layers. For example, for image corruption, it makes more sense to fine-tune the first layer of the model, since it’s
more of an input-level shift in data distribution <d-cite key="lee2022surgical"></d-cite>. The figure below shows more of these examples. Chelsea’s 
advice is to first <strong>train the last layer</strong>, and then <strong>fine-tune the entire network</strong> <d-cite key="kumar2022fine"></d-cite>, since fine-tuning can 
distort pre-trained features.</p>

<figure class="figure col-sm-12 float-right">
    <img src="/assets/img/blog/cs330/3/tl_dataset_size.png" class="img-fluid" alt="Alt text.">
    <figcaption class="figure-caption text-center">The effect of fine-tuning with different dataset sizes.</figcaption>
</figure>

<p>However, one big disadvantage to fine-tuning is that <strong>it does not work well for very small target datasets</strong>. An 
example of this can be seen in the figure above. Luckily, this is where meta learning comes into play!</p>

<hr>

<h2 id="introduction-to-meta-learning">Introduction to meta learning</h2>

<p>With transfer learning, we initialize a model and then hope that it helps to solve the target task, by for example 
fine-tuning it. With meta-learning, we are asking the question of whether we can <strong>explicitly optimize for transferability</strong>.
Thus, given a set of training tasks, can we optimize the ability to learn these tasks quickly, so that we can learn <em>new</em> 
tasks quickly too.</p>

<p>When learning a task, we are very roughly mapping a task dataset to a set of model parameters through a function 
$\mathcal{D}^\mathrm{tr}_i \rightarrow \theta$. In meta learning, we are asking whether we can optimize this function
for a small $\mathcal{D}_i^\mathrm{tr}$.</p>

<p>There are two ways to view meta-learning algorithms:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <p><b>(1) Mechanistic view</b></p>
        <p>Construct a deep network that can read in an entire dataset and make predictions for new datapoints. Training this
        network uses a meta-dataset, which itself consists of many datasets, each for a different task.</p>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <p><b>(2) Probabilistic view</b></p>
        <p>Extract shared prior knowledge from a set of tasks that allows for efficient learning of new tasks. Then, learning a 
        new task uses this prior and a (small) training set to infer the most likely posterior parameters.</p>
    </div>
</div>

<h3 id="a-probabilistic-view-on-meta-learning">A probabilistic view on meta learning</h3>

<div>
<figure class="figure col-sm-5 float-right">
    <img src="/assets/img/blog/cs330/3/mtl_graphical_model.png" class="img-fluid" alt="Alt text.">
    <figcaption class="figure-caption text-center">Graphical model of multi-task- and meta-learning.</figcaption>
</figure>

<p>Expanding on the probabilistic (Bayesian) view of meta learning, let’s look at a graphical model for multi-task and
meta learning. To quickly recap what a graphical model represents, consider two random variables $X$ and $Y$. If there
is an arrow from $X$ to $Y$ in the graphical model, it means that $p(Y\vert X) \neq P(Y)$, meaning that the random 
variable $Y$ is dependent on $X$. Furthermore, you can nest certain variables (the rounded squared squares with $i$ 
and $j$) in the figure on the right, if you would like to repeat them for different indices.</p>
</div>

<p>Now we can start interpreting the graphical model for multi-task learning. Merging the training and testing sets, we 
immediately see that the target variable of datapoint $j$ for task $i$, denoted as $y_{i,j}$, is dependent on both the 
input data $x_{i,j}$ and the task-specific “true” parameter(s) $\phi_i$. The only difference between the training and 
testing data is that the target variables of the test dataset are not observed, whilst the others are all latent 
variables (unobserved). As we saw, for each task, we have task-specific true parameters $\phi_i$. However, if we share
some <strong>common structure</strong> between multiple tasks, we can condition these parameters on this common structure. Hence, 
$\theta$ defines the parameters related to the shared structure between different tasks.</p>

<p>This shared structure means that task parameters $\phi_{i_1}, \phi_{i_2}$ become independent when conditioning on the 
shared parameters $\theta$: $\phi_{i_1} \perp \phi_{i_2} \vert \theta$. Furthermore, the entropy of $p(\phi_i \vert \theta)$
is lower than $p(\phi_i)$, as there is less distributional noise from common structure.</p>

<p>Let’s now have a thought exercise. If we can identify $\theta$, then when should learning $\phi_i$ be faster than 
learning from scratch? Let’s think about one extreme. If the shared information fully describes the task-specific 
information, we would see that $p(\phi_i \vert \theta) = p(\phi_i \vert \phi_i) = 1$. From that, we can see that it is
faster if there is a lot of common information about the task that is captured by $\theta$. In a more general case, if 
the entropy $\mathcal{H}(p(\phi_i\vert\theta)) = 0$, meaning that you can predict $\phi_i$ with 100% accuracy given 
$\theta$, you can learn the fastest. However, this does not necessarily mean that $\phi_i = \theta$!</p>

<p>From all of this, we can define <strong>structure</strong> as a <strong>statistical dependence</strong> on <strong>shared latent information 
$\theta$.</strong> Let’s now see some examples of the type of information that $\theta$ may contain.</p>

<ul>
  <li>In a multi-task sinusoid problem, $\theta$ corresponds to the family of sinusoid functions, which is everything except the phase and amplitude.</li>
  <li>In a multi-language machine translation problem, $\theta$ corresponds to the family of all language pairs.</li>
</ul>

<p>Note that $\theta$ is <strong>narrower</strong> than the space of all possible functions!</p>

<p>We will discuss this probabilistic view on meta learning more in later lectures, but for the remainder of this lecture, 
we will switch back to the mechanistic view.</p>

<h3 id="how-does-meta-learning-work">How does meta learning work?</h3>

<figure class="figure col-sm-12 float-right">
    <img src="/assets/img/blog/cs330/3/ml_example.png" class="img-fluid" alt="Alt text.">
    <figcaption class="figure-caption text-center">Example of a meta-learning object classification problem.</figcaption>
</figure>

<p>Let’s consider an image classification problem, where you have different tasks. In the problem above, the different 
tasks contain different images to classify. For the (meta-)training process, we have tasks $\mathcal{T}_1, \mathcal{T}_2, \dots, \mathcal{T}_n$
and we would like to do meta-testing on a new task $\mathcal{T}_\mathrm{test}$. The goal is to learn to solve task 
$\mathcal{T}_\mathrm{test}$ more quickly than from scratch. We can then test after training on the few examples from 
the new (in this case testing) task $\mathcal{T}_\mathrm{test}$. Of course, this problem settings generalizes to any 
other machine learning problem like regression, language generation, skill learning, etc.</p>

<p>The <b>key assumption</b> here is that meta-training tasks and meta-testing tasks are drawn i.i.d. from the same task 
distribution $\mathcal{T}_1, \dots, \mathcal{T}_n,\mathcal{T}_\mathrm{test} \sim p(\mathcal{T})$, meaning that tasks 
must share structure.</p>

<p>Analogous to more data in machine learning, the more tasks, the better! You can say that meta learning is transfer 
learning with many source tasks.</p>

<p>The following is some terminology for different things you will hear when talking about meta learning:</p>

<ul>
  <li>The task-specific training set $\mathcal{D}_i^\mathrm{tr}$ is often referred to as the <em>support set</em> or the <em>context</em>.</li>
  <li>The task test dataset $\mathcal{D}_i^\mathrm{test}$ is called the <em>query set</em>.</li>
  <li>
<em>k-shot learning</em> refers to learning with <strong>k</strong> examples per class.</li>
</ul>

<h3 id="a-general-recipe-for-meta-learning-algorithms">A general recipe for meta learning algorithms</h3>

<p>Let’s formalize meta supervised learning in a mechanistic view. We are looking for a function 
$y^\mathrm{ts} = f_\theta(\mathcal{D}^\mathrm{tr}, x^\mathrm{ts})$, which is trained on the data $\{\mathcal{D}_i\}_{i=1,\dots,n}$. 
This formulation reduces the meta-learning problem to the design and optimization of $f_\theta$.</p>

<p>To approach a problem using meta learning, you will need to decide on two steps:</p>

<ol>
  <li>What is my form of $f_\theta(\mathcal{D}^\mathrm{tr}, x^\mathrm{ts})$?</li>
  <li>How do I optimize the meta-parameters $\theta$ with respect to the maximum-likelihood objective using meta-training data.</li>
</ol>

<p>The following lectures will focus on core methods for meta learning and unsupervised pre-trained methods!</p>

<hr>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Lars C.P.M. Quaedvlieg. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <d-bibliography src="/assets/bibliography/blog/cs330/2024-03-03-tl-ml.bib"></d-bibliography>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JKH10LEP3Y"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-JKH10LEP3Y');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
