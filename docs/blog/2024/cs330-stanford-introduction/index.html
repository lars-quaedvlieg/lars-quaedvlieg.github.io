<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS-330: Deep Multi-Task and Meta Learning - Introduction | Lars C.P.M. Quaedvlieg</title>
    <meta name="author" content="Lars C.P.M. Quaedvlieg" />
    <meta name="description" content="I have been incredibly interested in the recent wave of multimodal foundation models, especially in robotics and sequential decision-making. Since I never had a formal introduction to this topic, I decided to audit the Deep Multi-Task and Meta Learning course, which is taught yearly by Chelsea Finn at Stanford. I will mainly document my takes on the lectures, hopefully making it a nice read for people who would like to learn more about this topic!" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="Lars C.P.M. Quaedvlieg" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Lars C.P.M. Quaedvlieg | CS-330: Deep Multi-Task and Meta Learning - Introduction" />
    <meta property="og:url" content="http://localhost:4000/blog/2024/cs330-stanford-introduction/" />
    <meta property="og:description" content="I have been incredibly interested in the recent wave of multimodal foundation models, especially in robotics and sequential decision-making. Since I never had a formal introduction to this topic, I decided to audit the Deep Multi-Task and Meta Learning course, which is taught yearly by Chelsea Finn at Stanford. I will mainly document my takes on the lectures, hopefully making it a nice read for people who would like to learn more about this topic!" />
    <meta property="og:image" content="/assets/img/profile.png" />
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="CS-330: Deep Multi-Task and Meta Learning - Introduction" />
    <meta name="twitter:description" content="I have been incredibly interested in the recent wave of multimodal foundation models, especially in robotics and sequential decision-making. Since I never had a formal introduction to this topic, I decided to audit the Deep Multi-Task and Meta Learning course, which is taught yearly by Chelsea Finn at Stanford. I will mainly document my takes on the lectures, hopefully making it a nice read for people who would like to learn more about this topic!" />
    <meta name="twitter:image" content="/assets/img/profile.png" />
    <meta name="twitter:site" content="@lars_quaedvlieg" />
    <meta name="twitter:creator" content="@lars_quaedvlieg" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/default.css" media="" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2024/cs330-stanford-introduction/">
    
    <!-- Dark Mode -->
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "CS-330: Deep Multi-Task and Meta Learning - Introduction",
      "description": "I have been incredibly interested in the recent wave of multimodal foundation models, especially in robotics and sequential decision-making. Since I never had a formal introduction to this topic, I decided to audit the Deep Multi-Task and Meta Learning course, which is taught yearly by Chelsea Finn at Stanford. I will mainly document my takes on the lectures, hopefully making it a nice read for people who would like to learn more about this topic!",
      "published": "March 1, 2024",
      "authors": [
        {
          "author": "Lars C.P.M. Quaedvlieg",
          "authorURL": "https://lars-quaedvlieg.github.io/",
          "affiliations": [
            {
              "name": "EPFL",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Lars C.P.M. Quaedvlieg</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Curriculum Vitae</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>CS-330: Deep Multi-Task and Meta Learning - Introduction</h1>
        <p>I have been incredibly interested in the recent wave of multimodal foundation models, especially in robotics and sequential decision-making. Since I never had a formal introduction to this topic, I decided to audit the Deep Multi-Task and Meta Learning course, which is taught yearly by Chelsea Finn at Stanford. I will mainly document my takes on the lectures, hopefully making it a nice read for people who would like to learn more about this topic!</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#lectures">Lectures</a></div>
            <div><a href="#why-multi-task-and-meta-learning">Why multi-task and meta-learning?</a></div>
            <div><a href="#what-are-tasks">What are tasks?</a></div>
            <div><a href="#references">References</a></div>
            
          </nav>
        </d-contents>

        <h2 id="introduction">Introduction</h2>

<p>The course <a href="https://cs330.stanford.edu/" target="_blank" rel="noopener noreferrer">CS 330: Deep Multi-Task and Meta Learning</a>, by <a href="https://ai.stanford.edu/~cbfinn/" target="_blank" rel="noopener noreferrer">Chelsea Finn</a>, is taught
on a yearly basis and discusses the foundations and current state of multi-task learning and meta learning.</p>

<p><strong><img class="emoji" title=":warning:" alt=":warning:" src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png" height="20" width="20"> Note:</strong> I am discussing the content of the edition in Fall 2023, which no longer includes reinforcement learning.
If you are interested in this, I will be auditing <a href="https://cs224r.stanford.edu/" target="_blank" rel="noopener noreferrer">CS 224R Deep Reinforcement Learning</a>
later this spring, which is also taught by <a href="https://ai.stanford.edu/~cbfinn/" target="_blank" rel="noopener noreferrer">Chelsea Finn</a>.</p>

<p>In an attempt to improve my writing skills and provide useful summaries/voice my opinions, I have decided to discuss 
the content of every lecture in this blog. In this post, I will give an overview of the course and why it is important 
for AI, especially now.</p>

<p>This course will focus on solving problems that are composed of multiple tasks, and studies how structure that arises from these multiple tasks can be leveraged to learn more efficiently/effectively, including:</p>

<ul>
  <li>Self-supervised pre-training for downstream few-shot learning and transfer learning.</li>
  <li>Meta-learning methods that aim to learn efficient learning algorithms that can learn new tasks quickly.</li>
  <li>Curriculum and lifelong learning, where the problem requires learning a sequence of tasks, leveraging their shared structure to enable knowledge transfer.</li>
</ul>

<hr>

<h2 id="lectures">Lectures</h2>

<p>The lecture schedule of the course is as follows:</p>
<ol>
  <li><a href="/blog/2024/cs330-stanford-mtl/">Multi-task learning</a></li>
  <li><a href="/blog/2024/cs330-stanford-tl-ml/">Transfer learning &amp; meta learning</a></li>
  <li><a href="/blog/2024/cs330-stanford-bbml-icl/">Black-box meta-learning &amp; in-context learning</a></li>
  <li><a href="/blog/2024/cs330-stanford-obml/">Optimization-based meta-learning</a></li>
  <li>Few-shot learning via metric learning</li>
  <li>Unsupervised pre-training for few-shot learning (contrastive)</li>
  <li>Unsupervised pre-training for few-shot learning (generative)</li>
  <li>Advanced meta-learning topics (task construction)</li>
  <li>Variational inference</li>
  <li>Bayesian meta-learning</li>
  <li>Advanced meta-learning topics (large-scale meta-optimization)</li>
  <li>Lifelong learning</li>
  <li>Domain Adaptation and Domain Generalization</li>
  <li>Frontiers &amp; Open Challenges</li>
</ol>

<p>I am excited to start discussing these topics in greater detail! Check this page regularly for updates, since I will 
link to new posts whenever they are available!</p>

<hr>

<h2 id="why-multi-task-and-meta-learning">Why multi-task and meta-learning?</h2>

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/blog/cs330/1/robotics_example.png" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<p>Robots are embodied in the real world, and must generalize across tasks. In order to do so, they need some common sense 
understanding and supervision can’t be taken for granted.</p>

<p>Earlier robotics and reinforcement research mainly focused on problems that required learning a task from scratch. This 
problem is even present in other fields, such as object detection or speech recognition. However, as opposed to these 
problems, <strong>humans are generalists</strong> that exploit common structures to solve new problems more efficiently.</p>

<p>Going beyond the case of generalist agents, deep multi-task and meta learning useful for any problems where a <strong>common 
structure</strong> can benefit the efficiency or effectiveness of a model. It can be impractical to develop models for each
specific task (e.g. each robot, person, or disease), especially if the data that you have access to for these individual
tasks is <strong>scarce</strong>.</p>

<p>If you need to <strong>quickly learn something new</strong>, you need to utilize prior experiences (e.g. few-shot learning) to make 
decisions.</p>

<p>But why now? Right now, with the speed of research advancements in AI, many researchers are looking into utilizing 
multi-model information to develop their models. Especially in robotics, foundation models seem <strong>the</strong> topic in 2024,
and many advancements have been made in the past year <d-cite key="zhao2023learning"></d-cite>, <d-cite key="open_x_embodiment_rt_x_2023"></d-cite>, <d-cite key="octo_2023"></d-cite>, <d-cite key="brohan2023rt"></d-cite>.</p>

<hr>

<h2 id="what-are-tasks">What are tasks?</h2>

<p>Given a dataset $\mathcal{D}$ and loss function $\mathcal{L}$, we hope to develop a model $f_\theta$. Different tasks 
can be used to train this model, with some simple examples being objects, people, objectives, lighting conditions, 
words, languages, etc.</p>

<p>The <strong>critical assumption</strong> here is that different tasks must share some common structure. However, in practice, this 
is very often the case, even for tasks that seem unrelated. For example the laws of physics and the rules of English
can be shared among many tasks.</p>

<ol>
  <li>The multi-task problem: Learn <strong>a set of tasks</strong> more quickly or more proficiently than learning them independently.</li>
  <li>Given data on previous task(s), learn <strong>a new task</strong> more quickly and/or more proficiently.</li>
</ol>

<blockquote>
  <p>Doesn’t multi-task learning reduce to single-task learning?</p>
</blockquote>

<p>This is indeed the case when aggregating data across multiple tasks, which is actually one approach to multi-task 
learning. However, what if you want to learn new tasks? And how do you tell the model which task to do? And what if 
aggregating doesn’t work?</p>

<hr>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Lars C.P.M. Quaedvlieg. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <d-bibliography src="/assets/bibliography/blog/cs330/2024-03-01-introduction.bib"></d-bibliography>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JKH10LEP3Y"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-JKH10LEP3Y');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
